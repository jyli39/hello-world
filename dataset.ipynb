{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from utils import select_triplet, select_car_triplet, get_all_hard_triplets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faces_YALE(data.Dataset):\n",
    "    def __init__(self, root, num_per_cls=11,\n",
    "                 transforms=None, train=True, test=False):\n",
    "        '''\n",
    "        获取图像路径，并根据训练，验证，测试划分数据\n",
    "        '''\n",
    "        self.test = test  # 是否是测试模式\n",
    "\n",
    "        # 获取文件路径\n",
    "        print('root: ', root)\n",
    "        imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "\n",
    "        # 文件名排序\n",
    "        imgs = sorted(imgs, key=lambda x: int(\n",
    "            re.match(r'.*s(\\d+)\\.png', x).group(1)))\n",
    "        print(imgs)\n",
    "\n",
    "        img_num = len(imgs)\n",
    "\n",
    "        # 随机打乱数据\n",
    "        # np.random.seed(100) # 设置随机种子，确定\n",
    "        # imgs = np.random.permutation(imgs) # Yale数据集暂时不能随机打乱\n",
    "\n",
    "        # 划分训练数据集和验证数据集7: 3\n",
    "        if self.test:\n",
    "            self.imgs = imgs\n",
    "        elif train:\n",
    "            self.imgs = imgs[:int(0.7 * img_num)]  # 前70%\n",
    "        else:\n",
    "            self.imgs = imgs[int(0.7 * img_num):]  # 后30%\n",
    "\n",
    "        # 数据中心化\n",
    "        if transforms is None:\n",
    "            normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "            # 测试数据集或者验证数据集无需数据增强\n",
    "            if self.test or train:  # or not train\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "            else:\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(256),\n",
    "                    T.RandomSizedCrop(224),\n",
    "                    T.RandomHorizontalFlip(),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        一次返回一张图片的数据和label\n",
    "        '''\n",
    "        img_path = self.imgs[index]\n",
    "        face_id = int(re.match(r'.*s(\\d+)\\.png', img_path).group(1))\n",
    "        # print('face id: ', face_id)\n",
    "        label = int(face_id / 11)\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)  # 对数据进行缩放、裁剪、增强，归一化的变换\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FACE_LFW(data.Dataset):\n",
    "    '''\n",
    "    处理LYW数据集, 通过自定义dataset读取数据\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 transforms=None,\n",
    "                 NUM_PER_CLS=20):\n",
    "        '''\n",
    "        初始化数据集\n",
    "        '''\n",
    "        self.num_per_cls = NUM_PER_CLS\n",
    "\n",
    "        # 获取文件路径\n",
    "        print('root: ', root)\n",
    "        imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "        self.imgs = imgs\n",
    "\n",
    "        # 数据中心化\n",
    "        if transforms is None:\n",
    "            self.transforms = T.Compose([\n",
    "                T.Resize(224),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "        else:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        通过索引获取数据和标签\n",
    "        '''\n",
    "        img_path = self.imgs[index]\n",
    "        label = int(index / self.num_per_cls)\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hard_Triplet(data.Dataset):\n",
    "    '''\n",
    "    基于FaceNet Hard Triplet\n",
    "    '''\n",
    "    def __init__(self, root, model_path, transform=None):\n",
    "        '''\n",
    "        hard triplets初始化, 数据预处理方式\n",
    "        '''\n",
    "        self.triplets = get_all_hard_triplets(root, model_path, 62, 20)\n",
    "\n",
    "        # 数据预处理\n",
    "        if transform == None:\n",
    "            self.transform = T.Compose([\n",
    "                T.Resize(224),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                            std=[0.229, 0.224, 0.225])])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        一次获取一个hard triplet\n",
    "        '''\n",
    "        triplet = self.triplets[index]\n",
    "        data = [self.transform(Image.open(img)) for img in triplet[:3]]\n",
    "        label = triplet[3:]\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回所有hard triplet数量\n",
    "        '''\n",
    "        return len(self.triplets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triplet(data.Dataset):\n",
    "    '''\n",
    "    每次随机产生一个triplet数据\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 num_cls=62,\n",
    "                 num_tripets=1000,\n",
    "                 limit=20,\n",
    "                 transforms=None,\n",
    "                 train=True,\n",
    "                 test=False):\n",
    "        '''\n",
    "        组织数据: 随机产生num_triplets个triplets\n",
    "        '''\n",
    "        self.test = test\n",
    "        self.triplets = [select_triplet(root, num_cls, limit, False)\n",
    "                         for i in range(num_tripets)]  # order: anchor, positive, negative\n",
    "        # print(self.triplets)\n",
    "\n",
    "        # 数据预处理\n",
    "        if transforms is None:\n",
    "            normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "            # 测试数据集或者验证数据集无需数据增强\n",
    "            if self.test or train:  # or not train\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "            else:  # 数据增强\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(256),\n",
    "                    T.RandomSizedCrop(224),\n",
    "                    T.RandomHorizontalFlip(),\n",
    "                    normalize,\n",
    "                    T.ToTensor()\n",
    "                ])\n",
    "        else:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        每次返回一个triplet\n",
    "        '''\n",
    "        triplet = self.triplets[index]\n",
    "        # print(triplet)\n",
    "        data = [self.transforms(Image.open(img_path))\n",
    "                for img_path in triplet[:3]]\n",
    "        label = triplet[3:]\n",
    "        # print(label)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回triplet数量\n",
    "        '''\n",
    "        return len(self.triplets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------Triplet for cars\n",
    "\n",
    "\n",
    "class Car_triplet(data.Dataset):\n",
    "    '''\n",
    "    汽车的Triplet数据集\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 label_path,\n",
    "                 label2img_path,\n",
    "                 num_triplets=5000):\n",
    "        '''\n",
    "        初始化数据集\n",
    "        '''\n",
    "        print('root: ', root)\n",
    "        self.labels = pickle.load(open(label_path, 'rb'))\n",
    "        print('total %d kinds of car.' % len(self.labels))\n",
    "        self.label2img = pickle.load(open(label2img_path, 'rb'))\n",
    "\n",
    "        # 生成triplets数据集\n",
    "        self.triplets = [select_car_triplet(root, self.labels, self.label2img)\n",
    "                         for i in range(num_triplets)]\n",
    "        # print(self.triplets)\n",
    "\n",
    "        normalize = T.Normali7ze(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        # 数据预处理\n",
    "        self.transforms = T.Compose([\n",
    "            T.Compose([\n",
    "                T.Resize(224),\n",
    "                T.CenterCrop(224),\n",
    "                T.ToTensor(),\n",
    "                normalize  # normalize与ToTensor能否改变顺序\n",
    "            ])\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        每次返回一个triplet\n",
    "        '''\n",
    "        triplet = self.triplets[index]\n",
    "        data = [self.transforms(Image.open(img)) for img in triplet[:3]]\n",
    "        label = triplet[3:]\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        返回triplet数量\n",
    "        '''\n",
    "        return len(self.triplets)\n",
    "\n",
    "\n",
    "# Car test dataset...\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     triplets = [select_car_triplet('car_train_data', 196) for i in tqdm(range(1000))]\n",
    "#     # print(triplets)\n",
    "#     for x in triplets:\n",
    "#         print(x)\n",
    "#     print('--Test done.')\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     labels = pickle.load(open('quali_labels.pkl', 'rb'))\n",
    "#     img2label = pickle.load(open('img_names2labels.pkl', 'rb'))\n",
    "#     label2img = pickle.load(open('label2img_names.pkl', 'rb'))\n",
    "#     # class_names = pickle.load(open('class_names.pkl', 'rb'))\n",
    "#     triplets = [select_car_triplet('car_train_data',\n",
    "#                                    labels,\n",
    "#                                    img2label,\n",
    "#                                    label2img) for i in range(100)]\n",
    "#     print(triplets)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e351b8f43a8051a413352beddec2a7234c5048dc672983c8d1a2c12b0911bb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
